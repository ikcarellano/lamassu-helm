domain: &DOMAIN dev.lamassu.io
debugMode: true
storageClassName: &STORAGE_CLASS_NAE "" # <----  Default Value

#Downstream TLS
tls:
  # type: selfSigned | letsEncrypt | external
  type: selfSigned
  selfSignedOptions:
    duration: "2160h"
  letsEncryptOptions:
    clusterIssuer: true
    issuer: false
  externalOptions:
    secretName: ""

postgres:
  hostname: ""
  port: 5432
  username: ""
  password: ""

auth: 
  oidc:
    frontend:
      clientId: "frontend"
      authority: https://dev.lamassu.io/auth/realms/lamassu
      awsCognito: 
        enabled: false
        hostedUiDomain: ""
    apiGateway:
      jwksUrl: https://auth:8443/auth/realms/lamassu/protocol/openid-connect/certs
  authorization:
    rolesClaim: realm_access.roles
    roles:
      admin: admin
      operator: operator
services:
  keycloak:
    enabled: true
    image: ghcr.io/lamassuiot/keycloak:dev
    adminCreds:
      username: "admin"
      password: "admin"
    initUsers:
      - username: "enroller"
        password: "enroller"
        roles:
          - "pki-admin" 
      - username: "operator"
        password: "operator"
  ui:
    image: ghcr.io/lamassuiot/lamassu-ui:dev
  ocsp:
    image: ghcr.io/lamassuiot/lamassu-ocsp:2.0.0
  ca:
    image: ghcr.io/lamassuiot/lamassu-ca:dev
    engine: "vault"
    aws:
      region: ""
      accessKeyId: ""
      secretAccessKey: ""
    aboutToExpire: 90
    periodicScan:
      enabled: true
      cron: "0 * * * *"
  deviceManager:
    image: ghcr.io/lamassuiot/lamassu-devmanager:dev
    minimumReenrollmentDays: 100
  dmsManager:
    image: ghcr.io/lamassuiot/lamassu-dmsmanager:dev
  openPolicyAgent:
    image: openpolicyagent/opa:0.37.1-envoy
    remLogger:
      image: ghcr.io/lamassuiot/opa-rem-logger:dev
  cloudProxy:
    image: ghcr.io/lamassuiot/lamassu-cloudproxy:2.0.0
  alerts:
    image: ghcr.io/lamassuiot/lamassu-alerts:2.0.0
    smtp:
      from: ""
      insecure: false
      enable_ssl: true
      username: ""
      password: ""
      host: ""
      port: 25
  awsConnector:
    image: lamassuiot/lamassu-aws-connector:2.0.0
    enabled: false
    name: "AWS default connector"
    aws:
      accessKeyId: ""
      secretAccessKey: ""
      defaultRegion: ""
      sqs:
        inboundQueueName: "lamassuResponse"
        outbountQueueName: ""
simulationTools:
  enabled: false
  virtualDevice:
    image: lamassuiot/lamassuiot-virtual-device:2.0.0
  virtualDms:
    image: lamassuiot/lamassuiot-virtual-dms:2.0.0

##############################
# Subcharts values
##############################

# https://github.com/bitnami/charts/tree/main/bitnami/rabbitmq
rabbitmq:
  enabled: true
  fullnameOverride: "rabbitmq"
  global:
    storageClass: *STORAGE_CLASS_NAE
  podAnnotations:
    reloader.stakater.com/auto: "true"
  auth:
    username: "user"
    password: "user"
    tls:
      enabled: true
      existingSecret: rabbitmq-upstream-cert

#https://developer.hashicorp.com/consul/docs/k8s/helm
consul:
  fullnameOverride: "consul" #If not set, resources are created using Release.Name (referenced in .tpl  as "fullname"). Since it is not possilbe to use Release.Name in .Values.yml file, overwrite to avoid issues
  global:
    enabled: true
    datacenter: lamassu-k8s
    tls:
      enabled: true
      enableAutoEncrypt: true
      verify: false
      caCert:
        secretName: ca-upstream-cert
  client:
    enabled: false
  server:
    serverCert:
      secretName: consul-upstream-cert
    affinity: "null" #set to null to remove affinity rule. By default consul only deploys 1 service per node. See: https://developer.hashicorp.com/consul/docs/k8s/helm#v-server-affinity
    # annotations: |
    #   "reloader.stakater.com/auto": "true"
    replicas: 3
    storageClassName: *STORAGE_CLASS_NAE
    extraConfig: |
      {
        "enable_agent_tls_for_checks": true
      }


#https://developer.hashicorp.com/vault/docs/platform/k8s/helm/configuration
vault:
  fullnameOverride: "vault" #If not set, resources are created using Release.Name (referenced in .tpl  as "fullname"). Since it is not possilbe to use Release.Name in .Values.yml file, overwrite to avoid issues
  global:
    enabled: true
    tlsDisable: false
  server:
    authDelegator:
      enabled: false
    affinity: ""
    annotations:
      reloader.stakater.com/auto: "true"
    extraVolumes:
      - type: secret
        name: vault-upstream-cert
    ha:
      enabled: true
      replicas: 3
      apiAddr: https://127.0.0.1:8200
      config: |
        ui = true
        listener "tcp" {
          address = "[::]:8200"
          cluster_address = "[::]:8201"
          tls_cert_file = "/vault/userconfig/vault-upstream-cert/tls.crt"
          tls_key_file  = "/vault/userconfig/vault-upstream-cert/tls.key"
          tls_client_ca_file = "/vault/userconfig/vault-upstream-cert/ca.crt"
        }

        storage "consul" {
          path = "vault/"
          address = "https://consul-server:8501"
          tls_ca_file = "/vault/userconfig/vault-upstream-cert/ca.crt"
        }

        service_registration "kubernetes" {}
  ui:
    enabled: true
  injector:
    enabled: false
